

\chapter{Mapping on superconducting quantum processors}
\label{sec:org0c87802}

In this chapter we will describe the superconducting quantum processor used in this thesis and its constraints. 
Although the work done in this thesis  could be apply to any quantum technology, we limit our study to the surface code 17 chip (Surface-17) developed by Leo Di Carlo's group at QuTech \cite{Versluis_2017}.
In addition, we will explain the mapping model and the metrics used in this work.

\section{Constraints of the Surface-17 chip}
\label{sec:org168a66d}
\subfile{chapters/constraints}

\section{Mapping model}
\label{sec:org19dc500}
In order to map quantum circuits on the superconducting quantum chip we will use the mapping model developed in our group \cite{Lao_2018}.
A mapping algorithm or mapper is an algorithm able to find a mapping solution given a quantum circuit and a target device.
We consider that a mapper is subdivided in three tasks: scheduler, initial placement and routing, as described in the \hyperref[sec:orgd680d43]{Mapping of quantum circuits} section.
Our procedure is modular, although the flow is restricted to the one described below.
The mapper is fully adaptable to any device constrain.
As we will explain, it also offers two different kinds of schedulers and three router possibilities, as well as the option of running or not the initial placement and another options related to the chip constrains.
We believe this solution will aid researchers to investigate the best mapping, with different configurations.
The mapping model works as follows.

\subsection{Initial placement}
\label{sec:org4fe48f6}

The first step is to map the virtual qubits (the ones of the circuit) to the physical ones (the ones in the quantum chip).
Once the mapper knows the qubits required by the algorithm, it will try to find the best initial placement for the given circuit, that is, the placement that requires less movements of qubits.
First, it will check the first set of two-qubit gates and their target qubits.
If those qubits are not NN, it will initiate an Integer Liner Programming (ILP) algorithm \cite{Lao_2018} to find the optimal initial placement.
This optimal initial placement tries to place the qubits in a way that the minimum number of qubit movements are required.


\subsection{Router}
\label{sec:org18105df}
The function of the router is to move non-neighbouring qubits to adjacent positions whenever they need to interact. To this purpose, our router inspects all the gates, one by one, looking for non-NN qubits interactions.
Whenever the router finds one, it will calculate several paths and select one of them. This path is selected based on the circuit depth, that is, the path that better interleaves with the previous operations.
Then, it will insert the SWAP operations (decomposed or not decomposed) required to follow the selected path.


There are three router options, and a different path is generated depending on the router option that was selected by the user:

\begin{enumerate}
\item \texttt{base} finds all the shortest paths and selects one of them randomly. The shortest paths are calculated based on the Manhattan distance, counting the number of steps that the qubits will need to move.
\item \texttt{minextend} finds all the shortest paths as well, but selects the one that will minimally increase the circuit depth. In this case, only gate dependencies are considered, not chip constraints that limits the parallelism.
\item The \texttt{minextendrc} approach is exactly the same as the second one, but taking into account the chip constraints when selecting the path.
\end{enumerate}


\subsection{Scheduler}
\label{sec:org2ec75f3}

The RC-scheduler will finally schedule the circuit using either an ALAP or an ASAP approach, depending on the user requirements.
It will take into account the chip parallelism constraints, as the ones described in \ref{sec:org168a66d}.

One downside factor regarding this methodology is that the mapper only takes into account one gate every time.
It does not look ahead in order to decide the best path for next iterations.
Or, what is the same, it does not always find the best mapping solution.
This limitation comes from the fact that, the more steps you are looking ahead while mapping, the more computationally complex will the mapper be.
We highlight that the mapping problem is an NP problem \cite{Siraichi_2018}.
Therefore, this method represents a viable solution, although a lot of future work should be done.

\section{New Mapping Metrics}
\label{sec:org27990de}
As mentioned in the \hyperref[sec:orgc729465]{Mapping metrics} section in the second chapter, we name \emph{mapping metrics} to those metrics used to assert the quality of a mapper and that are also used by the mapper algorithm as an heuristic.
In this section we will review the common metrics as the \textbf{number of SWAPs} or the \textbf{latency}, but we will also define -- and study in more detail -- some new mapping metrics that we incorporated, \textbf{probability of success} and \textbf{Quantum Volume}.

\subsection{Fidelity and probability of success}
\label{sec:org0c7b2c2}

\begin{figure}
    \centering

\resizebox{0.3\textwidth}{!}{
   \Qcircuit @C=1em @R=.7em {
&&&&&\mbox{fidelity}&&&&\mbox{prob. success}\\
&&&&&&&&&\\
\lstick{a} & \targ & \qw & \qw & \qw & \qw \ar@{.}[]+<0.75em,1em>;[d]+<0.75em,-9em> & \meter \ar@{.}[]+<2em,1em>;[d]+<2em,-9em> & \rstick{0} \qw&&\\
\lstick{b} & \ctrl{-1} & \targ & \qw & \qw & \qw & \meter & \rstick{0} \qw&&\\
\lstick{c} & \qw & \ctrl{-1} & \targ & \qw & \qw & \meter & \rstick{0} \qw&&\\
\lstick{d} & \qw & \qw & \ctrl{-1} & \targ & \qw & \meter & \rstick{0} \qw&&\\
\lstick{e} & \qw & \qw & \qw & \ctrl{-1} & \targ & \meter & \rstick{0} \qw&&\\
\lstick{f} & \qw & \qw & \qw & \qw & \ctrl{-1} & \meter & \rstick{1} \qw&&
}
}
\caption{Example of the fidelity and probability of success calculation in the Gray encoder quantum circuit}
\label{fig:latency_swaps_ex_orig}
\end{figure}

Fidelity and probability of success  are two different ways to measure the amount of errors that appear in a quantum system.
Fidelity considers the errors in the qubit superposition state and probability of success considers the errors after collapsing the quantum state in a measurement, therefore, it includes the measurement error as well.

Although not taking into account the measurement, the quantum fidelity metric is related with the probability of success.
Both compare two quantum states, but, while the success of an algorithm is a boolean metric -- either success or failure --, the fidelity returns a number of how different the states are.
How far is one state from the other.
As an analogy, if we consider the quantum states as vectors, the fidelity would be the dot product between them.
However, the fidelity between orthogonal states -- states that differ in rotations around the x-axis as \(| 0100 \rangle\), \(| 0001 \rangle\) and \(| 1111 \rangle\) -- is also 0.
In eq. \ref{eq:orge3c164e} the fidelity formula is shown to understand its behaviour.

\begin{equation}
\label{eq:orge3c164e}
{\displaystyle F(\rho ,\sigma )=\left(\operatorname {Tr} {\sqrt {{\sqrt {\rho }}\sigma {\sqrt {\rho }}}}\right)^{2},}
\end{equation}

where \(\rho =\sum _{i}p_{i}|i\rangle \langle i|\) and \(\sigma =\sum _{i}q_{i}|i\rangle \langle i|\).
These states are named \textbf{mixed states} and they are defined as the weighted sum of different pure states.
This is the general case in order to calculate the fidelity in any case.
But, for a situation with one of the states as pure state (\({\displaystyle \rho =|\psi _{\rho }\rangle \!\langle \psi _{\rho }|}\)) the calculation of fidelity reduces its complexity as it can be understood from eq. \ref{eq:org2703857}.
Eq. \ref{eq:org1f331e2} the next step of simplicity, the one in which both states are pure (\({\displaystyle \rho =|\psi _{\rho }\rangle \!\langle \psi _{\rho }|}, {\displaystyle \sigma =|\psi _{\sigma }\rangle \!\langle \psi _{\sigma }|} {\displaystyle \sigma =|\psi _{\sigma }\rangle \!\langle \psi _{\sigma }|}\)).


\begin{equation}
\label{eq:org2703857}
{\displaystyle F(\rho ,\sigma )=\operatorname {Tr} \left[{\sqrt {|\psi _{\rho }\rangle \langle \psi _{\rho }|\sigma |\psi _{\rho }\rangle \langle \psi _{\rho }|}}\right]^{2}=\langle \psi _{\rho }|\sigma |\psi _{\rho }\rangle \operatorname {Tr} \left[{\sqrt {|\psi _{\rho }\rangle \langle \psi _{\rho }|}}\right]^{2}=\langle \psi _{\rho }|\sigma |\psi _{\rho }\rangle .}
\end{equation}

\begin{equation}
\label{eq:org1f331e2}
{\displaystyle F(\rho ,\sigma )=|\langle \psi _{\rho }|\psi _{\sigma }\rangle |^{2}}
\end{equation}


We define probability of success as the probability of having the correct or expected results after running and measuring several times a quantum algorithm.
For instance, if the expected result of an algorithm is \texttt{0100} and the results are either \texttt{0001} or \texttt{1111} we will get a failure.
We will only get a success if the algorithm returns \texttt{0100}.
Then, in the previous example, if we get \texttt{0001}, \texttt{0100} and \texttt{1111} as results after running the algorithm three times the resulting probability of success will be \(\frac{1}{3}\).
This model was chosen because it is one of the most practical ways to include the measurement gate into the error analysis.
But, at the same time, we aware that this metric have a limitation: it cannot assert -- in just one run -- the success of an algorithm that ideally returns a quantum state different that either the ground or the excited state.
Once a quantum state is measured it collides in either ground or excited.
In order to extract the complete quantum state, several runs of the circuit should be done, inheriting the results as a probabilistic distribution or histogram.
For a state as \(0.3 | 0 \rangle + 0.7 | 1 \rangle\), after several measurements, we will get \texttt{0} a 30\% of the times and \texttt{1} 70\% of the times.
Accordingly, in order to calculate the probability of success, we will need to compare histograms instead of only one measured result.



In our study, we will use both metrics in order to calculate the amount of errors that arise from an algorithm.
As soon as fidelity is not taking into account the measurement errors, it is common that both metrics differ completely.
It could be the case that a quantum state is erroneous before the measurement and, then, due to the error added from the measurement the erroneous state would flip and converge into the expected state.
At the same time, a correct quantum state could be measured wrongly due to the measurement errors.

\subsection{Quantum Volume}
\label{sec:org3029336}

Another metric we think it can be useful for the mapping quality assessment is Quantum Volume \cite{Bishop_2017,Moll_2018}.
Quantum Volume is a metric developed by IBM to depict whether a device is able to run a quantum circuit or not.
Given the different hardware implementations and technologies in Quantum Computation (superconducting, ion-trap, spin qubits, \ldots{}), it is often difficult to benchmark the usefulness or power of quantum systems. 
The aim of Quantum Volume is to quantify the computational power of quantum devices. 
Consequently we will use it as a metric to measure the runnability of the quantum algorithms on the quantum devices.
But, while the device is the basis of the Quantum Volume metric, we fix our attention on the circuit.
Our purpose is to assert how the mapping procedure affects the runnability of a given circuit and to study how the Quantum Volume is related to the fidelity and the probability of success.

The general Quantum Volume formula is defined in eq. \ref{eq:general_qv} where \(N\) is the number of physical qubits and \(d(N)\) is the achievable circuit depth; the maximum circuit depth for which the results, after running it on some device, are correctable and useful.
\(d(N)\) depends on the number of qubits in the circuit as well as the error rate of the quantum device.
In our case, we want to relate the Quantum Volume of a device with the circuit.
Therefore, we define the \textbf{algorithms Quantum Volume} and the \textbf{runnability} of the quantum circuit on a given device.

\begin{equation}
\label{eq:general_qv}
V_Q = min (N, d(N))^2
\end{equation}

As with \(V_Q\), we initially derived the algorithm's Quantum Volume from the general equation \(V_Q\) (see eq. \ref{eq:orgc799c10}), although we will adapt it later.

\begin{equation}
\label{eq:orgc799c10}
V_Q^a = \min \left[ n,d \right]^2
\end{equation}

Note that \(d\) is not \(d(N)\) but the real depth of the given algorithm.
At the same time, \(n\) is the number of qubits required by the algorithm itself.

We aware that this approach has a limitation regarding the mapping of the quantum circuit.
As explained before, \(V_Q\) is able to take into account the sophistication of the mapping procedure.
It is inherited in the \emph{model algorithm}.
But, in this case, the \(V^a_Q\) of an algorithm before and after mapping will remain the same.
After mapping an algorithm, the usual effect is an increase in the depth or the number of operations.
Rare mapping methods consider the qubit addition in the technique.
And, even considering it, \(n\) is not often growing too much in comparison with \(d\).
In the current NISQ era, the quantum circuits need much less qubits than depth.
Therefore, most of the times, the minimum value between \(n\) and \(d\) will be \(n\).
As soon as \(V^a_Q\) is taking into account the minimum of them and the mapping procedure affects mostly to \(d\) we can conclude that this definition of \(V^a_Q\) is not considering the mapping in its results.

A simplified solution for this problem would be the \(V^a_Q\) definition as the multiplication between \(n\) and \(d\) (see eq. \ref{eq:org6aba4aa}).
Unfortunately, this approach has several drawbacks as well.
As Moll et al. point out \cite{Moll_2018}, extreme cases of high \(n\) and low \(d\) -- or the other way around -- lead to inconsistencies of the multiplication metric.
But, considering that most of our work is not going to be in any of these extreme cases and that we can avoid those outliers, we define the algorithm's Quantum Volume as:

\begin{equation}
\label{eq:org6aba4aa}
V_Q^a =  n \times d
\end{equation}

Finally, once the Quantum Volume of an algorithm is stated, we define runnability as the condition for which the \(V_Q\) should be bigger than \(V^a_Q\).
That is the condition that the computational power of the device should be bigger than the computational power required by the algorithm.

$$\text{Runnable if: } V_Q > V^a_Q \quad \quad \text{ when } N \ge n$$

For instance, in order to understand this concept, one may imagine the process of checking, whether or not, some cube with a given volume -- representing the algorithm -- would fit in a box -- the device --.
If the algorithm's box volume is smaller than the volume of the device's box, the algorithm's box will fit inside.

Indeed, one acceptable criticism of this definition is that, as \(V_Q\) and \(V^a_Q\) are finally defined in the previous sections, it seems that it is not really fair to compare them.
But, as soon as the general behaviour of both definitions of \(V^a_Q\) is the same we believe that this definition of runnability is mathematically correct and useful.
